## Variables that need to be set for this job:
## - gp_ver = Greenplum Major Version
## - passed = upstream job name that the artifacts need to pass before this job

- name: test_pxf-gp[[gp_ver]]_hdp2-secure-multi-impers_on_rhel8
  max_in_flight: 2
  plan:
  - in_parallel:
    - get: pxf_src
      passed: [[passed]]
      trigger: true
    - get: pxf_tarball
      resource: pxf_gp[[gp_ver]]_tarball_rhel8
      passed: [[passed]]
    - get: gpdb_package
      resource: gpdb[[gp_ver]]_rhel8_rpm_latest-0
      passed: [[passed]]
    - get: gpdb[[gp_ver]]-pxf-dev-rocky8-image
    - get: ccp_src
    - get: ccp-7-image
    - get: pxf-automation-dependencies
    - get: singlecluster
      resource: singlecluster-hdp2
    - get: gp6-python-libs
  - in_parallel:
    - do:
      - put: terraform_gpdb
        resource: terraform
        params:
          action: create
          delete_on_failure: true
          generate_random_name: true
          terraform_source: ccp_src/google/
          vars:
            PLATFORM: rocky8-gpdb[[gp_ver]]
            number_of_nodes: ((number_of_gpdb_nodes))
            extra_nodes: 1
            segments_per_host: 4
            instance_type: n1-standard-4
            ccp_reap_minutes: 120
            standby_master: true
      - task: generate_greenplum_cluster
        input_mapping:
          gpdb_rpm: gpdb_package
          terraform: terraform_gpdb
        file: ccp_src/ci/tasks/gen_cluster.yml
        image: ccp-7-image
        params:
          AWS_ACCESS_KEY_ID: ((tf-machine-access-key-id))
          AWS_SECRET_ACCESS_KEY: ((tf-machine-secret-access-key))
          AWS_DEFAULT_REGION: ((ud/common/aws-region))
          BUCKET_PATH: ((tf-bucket-path))
          BUCKET_NAME: ((ud/pxf/common/tf-bucket-name))
          PLATFORM: rocky8-gpdb[[gp_ver]]
          CLOUD_PROVIDER: google
          GPDB_RPM: true
      - in_parallel:
        - task: initialize_greenplum
          file: ccp_src/ci/tasks/gpinitsystem.yml
        - task: install_hadoop
          file: pxf_src/concourse/tasks/install_hadoop.yml
          image: gpdb[[gp_ver]]-pxf-dev-rocky8-image
          params:
            ACCESS_KEY_ID: ((tf-machine-access-key-id))
            SECRET_ACCESS_KEY: ((tf-machine-secret-access-key))
            IMPERSONATION: ((enable-impersonation-multinode))
    - task: generate_hadoop_cluster_1
      file: pxf_src/concourse/tasks/install_dataproc.yml
      params:
        GOOGLE_CREDENTIALS: ((ud/pxf/secrets/ccp-ci-service-account-key))
        GOOGLE_PROJECT_ID: ((ud/pxf/common/google-project-id))
        GOOGLE_ZONE: ((ud/pxf/common/google-zone))
        IMAGE_VERSION: ((dataproc-image-version))
        KERBEROS: ((kerberos-enabled))
        ccp_reap_minutes: 120
    - task: generate_hadoop_cluster_2
      file: pxf_src/concourse/tasks/install_dataproc.yml
      output_mapping:
        dataproc_env_files: dataproc_2_env_files
      params:
        GOOGLE_CREDENTIALS: ((ud/pxf/secrets/kerberos-ccp-ci-service-account-key))
        GOOGLE_PROJECT_ID: ((ud/pxf/common/kerberos-google-project-id))
        GOOGLE_ZONE: ((ud/pxf/common/kerberos-google-zone))
        HADOOP_USER: gpuser
        IMAGE_VERSION: ((dataproc-image-version))
        INITIALIZATION_SCRIPT: gs://data-gpdb-ud-kerberos-scripts/scripts/initialization-for-kerberos.sh
        INSTANCE_TAGS: bosh-network,data-gpdb-ud-access
        KERBEROS: ((kerberos-enabled))
        KEY: dataproc-kerberos-key
        KEYRING: dataproc-kerberos
        ccp_reap_minutes: 120
        NO_ADDRESS: false
        PROXY_USER: gpuser
        SECRETS_BUCKET: ((ud/pxf/secrets/kerberos-pxf-secrets-bucket-name))
  - do: # Generate IPA Hadoop cluster
    - put: terraform_ipa_hadoop
      params:
        action: create
        generate_random_name: true
        terraform_source: pxf_src/concourse/terraform/ipa-multinode-hadoop
        vars:
          gcp_project: ((ud/pxf/common/ipa-google-project-id))
    - task: generate_multinode_hadoop_cluster
      file: pxf_src/concourse/tasks/install_multinode_hadoop.yml
      image: gpdb[[gp_ver]]-pxf-dev-rocky8-image
      params:
        ANSIBLE_VAR_gcp_storage_bucket: ((ud/pxf/common/build-resources-bucket-name))
        ANSIBLE_VAR_ipa_password: ((ud/pxf/secrets/ipa-password))
        ANSIBLE_VAR_ssl_store_password: ((ud/pxf/secrets/ssl-store-password))
  - task: setup_pxf
    input_mapping:
      terraform: terraform_gpdb
    file: pxf_src/concourse/tasks/install_pxf_on_ccp.yml
    image: ccp-7-image
    params:
      IMPERSONATION: true
      INSTALL_GPHDFS: false
      GP_VER: [[gp_ver]]
      KERBEROS: ((kerberos-enabled))
      PXF_JVM_OPTS: ((pxf-jvm-opts))
      PXF_BASE_DIR: /home/gpadmin/pxf-boot
  - task: test_pxf-gp[[gp_ver]]-hdp2-secure-multi-impers_on_rhel8
    image: gpdb[[gp_ver]]-pxf-dev-rocky8-image
    file: pxf_src/concourse/tasks/test_pxf_on_ccp.yml
    attempts: 2
    params:
      GOOGLE_PROJECT_ID: ((ud/pxf/common/google-project-id))
      ACCESS_KEY_ID: ((tf-machine-access-key-id))
      SECRET_ACCESS_KEY: ((tf-machine-secret-access-key))
      HIVE_VERSION: 2
      IMPERSONATION: true
      KERBEROS: ((kerberos-enabled))
      GP_VER: [[gp_ver]]
      GROUP: security,proxySecurity,proxySecurityIpa,multiClusterSecurity
      PXF_JVM_OPTS: ((pxf-jvm-opts))
      PXF_BASE_DIR: /home/gpadmin/pxf-boot
    on_success:
      in_parallel:
        steps:
        - *destroy_dataproc_1
        - *destroy_dataproc_2
        - *destroy_gpdb_cluster
        - *destroy_hadoop_cluster
